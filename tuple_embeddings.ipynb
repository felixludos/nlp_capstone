{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from allennlp.data import Vocabulary\n",
    "from allennlp.data.dataset_readers import SimpleLanguageModelingDatasetReader\n",
    "from allennlp.data.iterators import BasicIterator\n",
    "from allennlp.data.token_indexers import PretrainedBertIndexer\n",
    "from allennlp.data.tokenizers import WordTokenizer\n",
    "from allennlp.data.tokenizers.word_splitter import BertBasicWordSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from allennlp.modules.text_field_embedders import BasicTextFieldEmbedder\n",
    "from allennlp.modules.token_embedders import PretrainedBertEmbedder\n",
    "data_path = 'data/sorted_openbook_tuples.tsv'\n",
    "max_seq_length = 100\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "token_indexer = PretrainedBertIndexer(\n",
    "    pretrained_model='bert-base-uncased',\n",
    "    max_pieces=max_seq_length,  # TODO: find longest tuple in the tsv\n",
    "    do_lowercase=True\n",
    ")\n",
    "\n",
    "word_splitter = BertBasicWordSplitter()\n",
    "\n",
    "tokenizer = WordTokenizer(\n",
    "    word_splitter=word_splitter\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "reader = SimpleLanguageModelingDatasetReader(\n",
    "    tokenizer=tokenizer,\n",
    "    token_indexers={\"tokens\": token_indexer}\n",
    ")\n",
    "dataset = reader.read(data_path)\n",
    "\n",
    "# Left empty since we're using a pretrained model\n",
    "vocab = Vocabulary()\n",
    "\n",
    "# TODO: use BucketIterator\n",
    "iterator = BasicIterator(\n",
    "    batch_size=batch_size\n",
    ")\n",
    "iterator.index_with(vocab)\n",
    "\n",
    "bert_embedder = PretrainedBertEmbedder('bert-base-uncased')\n",
    "word_embeddings = BasicTextFieldEmbedder(\n",
    "    token_embedders={\"source\": bert_embedder}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': {'tokens': tensor([[  101,  4111,  2097,  4875,  2062,  4089,  2004,  3635,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  4111,  2097,  4875,  2062,  2004,  3635,  1997,  4111,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  2846,  2003,  5468,  1997,  3292,  2013, 10401,  2000,  2659,\n",
      "         10401,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  4044,  2003,  3147,  2012,  2474,  6916,  8525,  3207,  2917,\n",
      "          1014,  5445,  8292,  4877,  4173,   102,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  2087, 10381, 10626,  7361,  8523,  3215,  2024,  2179,  1999,\n",
      "          3727,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  4044,  2003,  3147,  2012,  2642,  2474,  6916,  8525,  3207,\n",
      "          2917,  1014,  5445,  8292,  4877,  4173,   102,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  2479,  2003,  2719,  2011, 13697,  2207,  2006,  4153,  2723,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  3467, 14017, 10074,  2063,  2003,  2006,  2285,  7398,  1999,\n",
      "         14130,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  2742,  2003,  9610,  8737,  2319, 23940, 10443,  2005,  9728,\n",
      "          2007,  6293,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  2087,  8399,  2015,  8577,  5485,  2058,  6993,  1997,  2051,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  3467,  2003,  1999,  2642, 14130,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101, 10098,  2003,  2719,  2011, 25416, 25533,  2011, 14541,  2422,\n",
      "          2046,  2367,  6087,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  4874,  2003,  3048,  2064,  3426,  2008,  4874,  1005,  1055,\n",
      "          3177,  3623,  1999,  4367,   102,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  2621, 14017, 10074,  2063,  2003,  2006,  2238,  7398,  1999,\n",
      "          2642, 14130,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101, 10162,  4044,  2003,  3147,  2012,  2642,  2474,  6916,  8525,\n",
      "          3207,  2917,  1014,  5445,  8292,  4877,  4173,   102,     0,     0,\n",
      "             0],\n",
      "        [  101,  3392,  1011,  3930,  7635,  2097,  2468,  2004,  3815,  1997,\n",
      "          2800,  2300,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  4044,  2003,  3147,  2012,  2642,  2474,  6916,  8525,  3207,\n",
      "          2917,  1014,  5445,  8292,  4877,  4173,  2076,  2087,   102,     0,\n",
      "             0],\n",
      "        [  101, 15065,  2846,  2003,  5468,  1997,  7471,  3292,  2013,  2152,\n",
      "         10401,  2000,  2659, 10401,   102,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  2754,  2003,  1999, 18804,  5302, 14536, 25229,  2832,  1997,\n",
      "          4176,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  2154,  2003,  5020,  2000,  2484,  2847,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  2028,  2154,  2003,  5020,  2000,  2484,  2847,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  4044,  2003,  3147,  2012,  2642,  2474,  6916,  8525,  3207,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  4044,  2003,  3147,  2012,  2642,  2474,  6916,  8525,  3207,\n",
      "          2917,  1014,  5445,  8292,  4877,  4173,  2076,  2087,  1997,  2095,\n",
      "           102],\n",
      "        [  101,  5749,  2024,  3120,  1997,  7713,  2005,  2235,  4176,  1999,\n",
      "          4044,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  2087,  8399,  2015,  8577,  5485,  2058,  2146,  6993,  1997,\n",
      "          2051,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  6912,  2038,  3893,  4254,  2006,  2303,  1005,  1055,  3997,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  2846,  2003,  5468,  1997,  7471,  3292,  2013,  2152, 10401,\n",
      "          2000, 10401,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101, 29476,  7971,  2038,  3893,  4254,  2006,  3269,  1005,  1055,\n",
      "          6147,  1005,  3930,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  4044,  2003,  3147,  2012,  2474,  6916,  8525,  3207,  2917,\n",
      "          1014,  5445,  8292,  4877,  4173,  2076,  2087,   102,     0,     0,\n",
      "             0],\n",
      "        [  101, 15065,  2846,  2003,  5468,  1997,  7471,  3292,  2000, 10401,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101, 15174,  2121, 19884,  2943,  2005, 15174,  2075,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  2846,  2003,  5468,  1997,  3292,  2013, 10401,  2000, 10401,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0]]), 'tokens-offsets': tensor([[ 1,  2,  3,  4,  5,  6,  7,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  0,  0,  0,  0,  0,  0],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10,  0,  0,  0,  0],\n",
      "        [ 1,  2,  3,  4,  8,  9, 10, 11, 14,  0,  0,  0,  0,  0],\n",
      "        [ 1,  6,  7,  8,  9, 10,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 1,  2,  3,  4,  5,  9, 10, 11, 12, 15,  0,  0,  0,  0],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9,  0,  0,  0,  0,  0],\n",
      "        [ 1,  4,  5,  6,  7,  8,  9, 10,  0,  0,  0,  0,  0,  0],\n",
      "        [ 1,  2,  6,  7,  8,  9, 10, 11,  0,  0,  0,  0,  0,  0],\n",
      "        [ 1,  3,  4,  5,  6,  7,  8,  9,  0,  0,  0,  0,  0,  0],\n",
      "        [ 1,  2,  3,  4,  5,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 1,  2,  3,  4,  6,  7,  8,  9, 10, 11, 12,  0,  0,  0],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,  0],\n",
      "        [ 1,  4,  5,  6,  7,  8,  9, 10, 11,  0,  0,  0,  0,  0],\n",
      "        [ 1,  2,  3,  4,  5,  6, 10, 11, 12, 13, 16,  0,  0,  0],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11,  0,  0,  0],\n",
      "        [ 1,  2,  3,  4,  5,  9, 10, 11, 12, 15, 16, 17,  0,  0],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,  0],\n",
      "        [ 1,  2,  3,  7,  8,  9, 10,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 1,  2,  3,  4,  5,  6,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 1,  2,  3,  4,  5,  9,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 1,  2,  3,  4,  5,  9, 10, 11, 12, 15, 16, 17, 18, 19],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10,  0,  0,  0,  0],\n",
      "        [ 1,  3,  4,  5,  6,  7,  8,  9, 10,  0,  0,  0,  0,  0],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9,  0,  0,  0,  0,  0],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11,  0,  0,  0],\n",
      "        [ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12,  0,  0,  0],\n",
      "        [ 1,  2,  3,  4,  8,  9, 10, 11, 14, 15, 16,  0,  0,  0],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9,  0,  0,  0,  0,  0],\n",
      "        [ 2,  3,  4,  5,  7,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9,  0,  0,  0,  0,  0]]), 'tokens-type-ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]])}}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "zeros_like() received an invalid combination of arguments - got (dict), but expected one of:\n * (Tensor input, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (Tensor input, bool requires_grad)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-6a1eff9a4cfc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minstance\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp_capstone/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp_capstone/lib/python3.7/site-packages/allennlp/modules/text_field_embedders/basic_text_field_embedder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, text_field_input, num_wrapping_dims)\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0;31m# is bijective and just use the key directly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext_field_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                 \u001b[0mtoken_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m             \u001b[0membedded_representations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded_representations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp_capstone/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp_capstone/lib/python3.7/site-packages/allennlp/modules/token_embedders/bert_token_embedder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, offsets, token_type_ids)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;31m# pylint: disable=arguments-differ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtoken_type_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0mtoken_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0minput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: zeros_like() received an invalid combination of arguments - got (dict), but expected one of:\n * (Tensor input, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (Tensor input, bool requires_grad)\n"
     ]
    }
   ],
   "source": [
    "for instance in iterator(dataset, num_epochs=1):\n",
    "    print(instance)\n",
    "    embeddings = word_embeddings(tokens)\n",
    "    print(instance.as_tensor_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
