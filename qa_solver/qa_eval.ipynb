{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, time\n",
    "import numpy as np\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from gensim.models.wrappers import FastText\n",
    "import gensim\n",
    "import word_util as wtil\n",
    "# import fastText\n",
    "from collections import Counter\n",
    "torch.set_printoptions(linewidth=120)\n",
    "np.set_printoptions(linewidth=120, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lang = fastText.load_model('../../fastText/wiki.en.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cosd(x,y):\n",
    "    if x.ndimension() == 1:\n",
    "        x = x.unsqueeze(0)\n",
    "    if y.ndimension() == 1:\n",
    "        y = y.unsqueeze(0)\n",
    "    x = F.normalize(x, 2, -1)\n",
    "    y = F.normalize(y, 2, -1)\n",
    "    return -x @ y.transpose(-1,-2)/2+.5\n",
    "def l2(x,y):\n",
    "    if x.ndimension() == 1:\n",
    "        x = x.unsqueeze(0)\n",
    "    if y.ndimension() == 1:\n",
    "        y = y.unsqueeze(0)\n",
    "    x = x.unsqueeze(-2)\n",
    "    y = y.unsqueeze(-3)\n",
    "    return (x-y).pow(2).mean(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_tokens(s):\n",
    "    s = s.lower()\n",
    "    if s[-1] in {'.','?'}:\n",
    "        s = s[:-1]\n",
    "    s = s.split(' ')\n",
    "    return s\n",
    "def topk(query,k=5):\n",
    "    picks = wtil.tfidf(Counter(filter_tokens(query)),full_bag)[:k]\n",
    "    return [w for w,s in picks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(293, 2481, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_name = '8th'\n",
    "if ds_name == 'elem':\n",
    "    root = '../data/questions/AI2-Elementary-NDMC-Feb2016-Train.jsonl'\n",
    "    lookup = '../../train_elem_tokens_emb.pth.tar'\n",
    "elif ds_name == '8th':\n",
    "    root = '../data/questions/AI2-8thGr-NDMC-Feb2016-Train.jsonl'\n",
    "    lookup = '../../train_8thgr_tokens_emb.pth.tar'\n",
    "else:\n",
    "    raise Exception('unknown dataset')\n",
    "    \n",
    "questions = wtil.load_questions(root)\n",
    "lookup = torch.load(lookup)\n",
    "\n",
    "full_bag = lookup['bag']\n",
    "\n",
    "lang = dict(zip(lookup['words'], lookup['vecs']))\n",
    "len(questions), len(full_bag), len(lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# questions = wtil.load_questions(root)\n",
    "# full_bag = Counter()\n",
    "# for q in questions:\n",
    "#     tokens = set(filter_tokens(q['question']['stem']))\n",
    "#     for a in q['question']['choices']:\n",
    "#         tokens.update(filter_tokens(a['text']))\n",
    "#     full_bag.update(tokens)\n",
    "# len(full_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46460, torch.Size([46460, 300]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = torch.load('../../fast_table.pth.tar')\n",
    "rows = table['rows']\n",
    "elements = table['elements']#np.array(table['elements'])\n",
    "vecs = torch.from_numpy(table['vecs']).float()\n",
    "len(elements), vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(286387, 49346, torch.Size([49346, 300]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oie = torch.load('../../oie_table.pth.tar')\n",
    "rows.extend(oie['rows'])\n",
    "elements.extend(oie['elements'])\n",
    "vecs = torch.cat([vecs, torch.from_numpy(oie['vecs'])],0)\n",
    "len(rows), len(elements), vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46460, torch.Size([46460, 300]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements = np.array(elements)\n",
    "table = dict(zip(elements,vecs))\n",
    "len(table.keys()), vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "mentions = {}\n",
    "for i, row in enumerate(rows):\n",
    "    for w in row:\n",
    "        if w not in mentions:\n",
    "            mentions[w] = []\n",
    "        mentions[w].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_connections(picks):\n",
    "    matches = set()\n",
    "    for q in picks:\n",
    "        matches.update(mentions[q])\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_closest(query, vecs, k=2):\n",
    "    \n",
    "    D = l2(query, vecs)\n",
    "    return torch.topk(D,k,dim=-1,largest=False, sorted=False)\n",
    "\n",
    "def convert(words, lang):\n",
    "    return torch.stack([lang[w] for w in words])\n",
    "    return torch.from_numpy(np.stack([lang.get_word_vector(w) for w in words])).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q = questions[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['working', 'company', 'testing', 'medicine', 'heal']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = topk(q['question']['stem'])\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 300])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = convert(words, lang)\n",
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls = get_closest(v, vecs)[1]\n",
    "cls.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1852, 21195],\n",
       "        [ 1087, 11452],\n",
       "        [ 1434, 21867],\n",
       "        [ 8084, 48455],\n",
       "        [31850, 23661]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1906"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conns = get_connections(elements[cls].reshape(-1))\n",
    "len(conns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1302"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wopts = set()\n",
    "for i in conns:\n",
    "    wopts.update(rows[i])\n",
    "wopts = list(wopts)\n",
    "len(wopts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1302, 300])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opts = torch.from_numpy(np.stack([table[w] for w in wopts])).float()\n",
    "opts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lbls = []\n",
    "for a in q['question']['choices']:\n",
    "    lbl = a['label']\n",
    "    v = convert(topk(a['text']), lang).view(-1,300)\n",
    "    nb = get_closest(v, opts, k=10)[0]\n",
    "    conf = 1/nb.mean()\n",
    "    lbls.append((lbl,conf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', tensor(17.5232)),\n",
       " ('B', tensor(21.1525)),\n",
       " ('C', tensor(18.2112)),\n",
       " ('D', tensor(28.0311))]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol = sorted(lbls, key=lambda x: x[1])[-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def solve(q):\n",
    "    \n",
    "    words = topk(q['question']['stem'])\n",
    "    \n",
    "    v = convert(words, lang)\n",
    "    \n",
    "    cls = get_closest(v, vecs)[1]\n",
    "    \n",
    "    conns = get_connections(elements[cls].reshape(-1))\n",
    "    \n",
    "    wopts = set()\n",
    "    for i in conns:\n",
    "        wopts.update(rows[i])\n",
    "    wopts = list(wopts)\n",
    "    \n",
    "    opts = torch.from_numpy(np.stack([table[w] for w in wopts])).float()\n",
    "    \n",
    "    lbls = []\n",
    "    for a in q['question']['choices']:\n",
    "        lbl = a['label']\n",
    "        v = convert(topk(a['text']), lang).view(-1,300)\n",
    "        nb = get_closest(v, opts, k=10)[0]\n",
    "        conf = 1/nb.mean()\n",
    "        lbls.append((lbl,conf))\n",
    "    \n",
    "    sol = sorted(lbls, key=lambda x: x[1])[-1][0]\n",
    "    return sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true = [q['answerKey'] for q in questions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/293 0.0000\n",
      "11/293 0.3636\n",
      "21/293 0.3810\n",
      "31/293 0.3226\n",
      "41/293 0.2927\n",
      "51/293 0.2549\n",
      "61/293 0.2787\n",
      "71/293 0.2958\n",
      "81/293 0.2963\n",
      "91/293 0.2747\n",
      "101/293 0.2970\n",
      "111/293 0.2973\n",
      "121/293 0.3223\n",
      "131/293 0.3130\n",
      "141/293 0.3121\n",
      "151/293 0.3046\n",
      "161/293 0.2981\n",
      "171/293 0.3099\n",
      "181/293 0.3204\n",
      "191/293 0.3141\n",
      "201/293 0.3085\n",
      "211/293 0.3175\n",
      "221/293 0.3122\n",
      "231/293 0.3030\n",
      "241/293 0.3029\n",
      "251/293 0.3028\n",
      "261/293 0.3065\n",
      "271/293 0.3026\n",
      "281/293 0.2954\n",
      "291/293 0.2990\n"
     ]
    }
   ],
   "source": [
    "sols = []\n",
    "correct = 0\n",
    "for i, q in enumerate(questions):\n",
    "    sol = solve(q)\n",
    "    if sol == true[i]:\n",
    "        correct += 1\n",
    "    sols.append(sol)\n",
    "    if i % 10 == 0:\n",
    "        print('{}/{} {:.4f}'.format(i+1,len(questions), correct/(i+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 0.2969\n"
     ]
    }
   ],
   "source": [
    "print('Done {:.4f}'.format(correct/(i+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BDDBCCDCBDACDBDCDADBDBABDDBBDCBCBCCBCBCACDBDBABCBAAABBABCADDCBABCBCBDDCCCDCAABCDADABDADCCACCCDDCBBACDBCACCAAABABDCABCCDCDDACBBCBADDBCCACACCDADADDAACDBBCADCCBBDADBBDAABACABADCABDDDCDCBBDDDDACADAACBCACACBBBCBDCBCCACCCBCCACCADDCBBBABCABBACACDCBCCBCDCADADBABDACADABBDDCBBDCBDADBBCCCCCBBDCDCDDBCBCD\n"
     ]
    }
   ],
   "source": [
    "print(''.join(true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CDDADADDBABADCDCADCDDABDCABCBCDACBDDBCCDCDDCADCAABDACBACBBCDABDBDBCCCAACDABCABABDCCADCCAABBCADBCCBDCCCABCCCCCBCCDDABCDDDDAABAADDDDBCACDACCDDBCDDBBCABBCABDCDCDADCBAAADBADDBBDCDBBDCDDDADBBBCCCAADBBCCDCDBDBBDBDDCDCBACBACADDBBABBDDBDAAACBBACBAABBCDACDADCCBCCDDCAADAABBBBCDDCBDABDBBAAADDACACBDBDAAA\n"
     ]
    }
   ],
   "source": [
    "print(''.join(sols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# elem: 0.2894\n",
    "# true: CCACACCAABCBCCCDDABAAADADCBACBDCDCDDAACACDABAAACCDACBDBAACBCDAABCBABDADAACDBABBCDBADCADDACDBBCADBBDDDABACDDCACDCDAACCABDCBADAACDDBBADBDDACBCBBBDAACBBBBCDDABDBCDBDCDDCDDACCCACCCDBCBAAADCADCBBDADADCBBACCBBBCDBABADBACAACCBCDCBBCCBBADDAACCBDCCADCDCACACADDDDCACDDBBADCBBACBBCBADCBADBDBDAACBDCCBBACAADDCBDDDDDCBBBACADAADCCCBBACCACABCCABCDDCBDDCDDCCBBBABBABCBBBBDBBCCBBCCACBBCAACAAADBCDDCACBCABBDBCBABCDBDBCABCDBDBDAACACCDBDBADBBBBBDBBBBAC\n",
    "# pred: CBDABDDCBACBCACACCDBBADADDAAAADBADAACBBDACBDCCBCDCABADDACDADDDACDCDCBBBDCBBBCDBCDCDCCCDDACCDBACBBCBBBADBBDBCBCBDAACDCABDBCADCBADCADACACBBBADBCDDABAABACCDBBDAAADBBBBABCDBBAAADCBBBDCBDADBDAAADBCAADCBDBBABCDBABCCADDDDADDDAAADBDBBBDBBBBCCCACCDDBAACBADAAABBACACCAAADDCADCDBBDDDCBCCBCCBDBCBDDCDCAADBDBABDDDCDCBCCDCDADAABAADDBDDAABDDABDBBBABDAABACDAABBCDBACCBDBDDBBDCCAABAACACABDCABCACDBBADCCAACDCADBCADBAABCDCCADCDCADCADDADABDDACBDACBADDB\n",
    "\n",
    "# elem-full: 0.2847\n",
    "# pred: CBDABDDCBDCBBACACCDBBADADDCAAADAADBACBDDACBDCCDCDCABADDACDADDDACDCACBBBDCBBBCDBCDCDCCCDDACCDCAABBCBBBADBDDBCBCADAACDCABDBCADCBADCADABACBABADBCDBCBAABACADBBCAAADBBBBABCDBBAAADCABBDCBDADBDAAADBCAADCBDBBCACDBABCCADDDDADDDABADBDBBBDBBBBCCCACCDDBAACBADAAABBACACCAABDDCADCDBBDDDCBCCBCCBDBBADDCDCAADBDBABDDDCDCDCCDCDADAABAADDADDACBDDABDCBBABDACBDCDAABACDBACCBDBDBBBDCCAABAACACABDCABBACDBBADCCAACDCADBCCBBABBCDCCADBDAADCADDADABDDAABDACBCDDB\n",
    "\n",
    "# 8th: 0.3072\n",
    "# true: BDDBCCDCBDACDBDCDADBDBABDDBBDCBCBCCBCBCACDBDBABCBAAABBABCADDCBABCBCBDDCCCDCAABCDADABDADCCACCCDDCBBACDBCACCAAABABDCABCCDCDDACBBCBADDBCCACACCDADADDAACDBBCADCCBBDADBBDAABACABADCABDDDCDCBBDDDDACADAACBCACACBBBCBDCBCCACCCBCCACCADDCBBBABCABBACACDCBCCBCDCADADBABDACADABBDDCBBDCBDADBBCCCCCBBDCDCDDBCBCD\n",
    "# pred: BDDADABDBDBADCDCADCDCABBCABCBCBACBDDBCCDCDDCADCAABDABBDCBBCDABDBDBCDCAACDABCABCBDDADDCCAAABCAABBBBBCCCABCCCCCBCCDDABCADDDAABAADDDDBCACDACADDBCDBBDCABBCABDCDCDADCBAAADBADDBBDCDBBDCDDDADBBBCCCAADBBCCDCDBDBBDBDDCDCBACBACADDBBABBDDBDAAACBBACBAABBCDACDADCCBCCDDCAADAABBBBCDDCBDADDBBBAADDACACADBDAAD\n",
    "\n",
    "# 8th-full: 0.2969\n",
    "# pred: CDDADADDBABADCDCADCDDABDCABCBCDACBDDBCCDCDDCADCAABDACBACBBCDABDBDBCCCAACDABCABABDCCADCCAABBCADBCCBDCCCABCCCCCBCCDDABCDDDDAABAADDDDBCACDACCDDBCDDBBCABBCABDCDCDADCBAAADBADDBBDCDBBDCDDDADBBBCCCAADBBCCDCDBDBBDBDDCDCBACBACADDBBABBDDBDAAACBBACBAABBCDACDADCCBCCDDCAADAABBBBCDDCBDABDBBAAADDACACBDBDAAA\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
