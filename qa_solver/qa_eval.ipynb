{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, time\n",
    "import numpy as np\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from gensim.models.wrappers import FastText\n",
    "import gensim\n",
    "import word_util as wtil\n",
    "# import fastText\n",
    "from collections import Counter\n",
    "torch.set_printoptions(linewidth=120)\n",
    "np.set_printoptions(linewidth=120, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lang = fastText.load_model('../../fastText/wiki.en.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cosd(x,y):\n",
    "    if x.ndimension() == 1:\n",
    "        x = x.unsqueeze(0)\n",
    "    if y.ndimension() == 1:\n",
    "        y = y.unsqueeze(0)\n",
    "    x = F.normalize(x, 2, -1)\n",
    "    y = F.normalize(y, 2, -1)\n",
    "    return -x @ y.transpose(-1,-2)/2+.5\n",
    "def l2(x,y):\n",
    "    if x.ndimension() == 1:\n",
    "        x = x.unsqueeze(0)\n",
    "    if y.ndimension() == 1:\n",
    "        y = y.unsqueeze(0)\n",
    "    x = x.unsqueeze(-2)\n",
    "    y = y.unsqueeze(-3)\n",
    "    return (x-y).pow(2).mean(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_tokens(s):\n",
    "    s = s.lower()\n",
    "    if s[-1] in {'.','?'}:\n",
    "        s = s[:-1]\n",
    "    s = s.split(' ')\n",
    "    return s\n",
    "def topk(query,k=5):\n",
    "    picks = wtil.tfidf(Counter(filter_tokens(query)),full_bag)[:k]\n",
    "    return [w for w,s in picks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(432, 2805, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_name = 'elem'\n",
    "if ds_name == 'elem':\n",
    "    root = '../data/questions/AI2-Elementary-NDMC-Feb2016-Train.jsonl'\n",
    "    lookup = '../../train_elem_tokens_emb.pth.tar'\n",
    "elif ds_name == '8th':\n",
    "    root = '../data/questions/AI2-8thGr-NDMC-Feb2016-Train.jsonl'\n",
    "    lookup = '../../train_8thgr_tokens_emb.pth.tar'\n",
    "else:\n",
    "    raise Exception('unknown dataset')\n",
    "    \n",
    "questions = wtil.load_questions(root)\n",
    "lookup = torch.load(lookup)\n",
    "\n",
    "full_bag = lookup['bag']\n",
    "\n",
    "lang = dict(zip(lookup['words'], lookup['vecs']))\n",
    "len(questions), len(full_bag), len(lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# questions = wtil.load_questions(root)\n",
    "# full_bag = Counter()\n",
    "# for q in questions:\n",
    "#     tokens = set(filter_tokens(q['question']['stem']))\n",
    "#     for a in q['question']['choices']:\n",
    "#         tokens.update(filter_tokens(a['text']))\n",
    "#     full_bag.update(tokens)\n",
    "# len(full_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46460, torch.Size([46460, 300]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = torch.load('../../fast_table.pth.tar')\n",
    "rows = table['rows']\n",
    "elements = table['elements']#np.array(table['elements'])\n",
    "vecs = torch.from_numpy(table['vecs']).float()\n",
    "len(elements), vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "added_path = '../../filtered.pth.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 651 tuples\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(283245, 47211, torch.Size([47211, 300]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "added = torch.load(added_path)\n",
    "print('Adding {} tuples'.format(len(added['rows'])))\n",
    "rows.extend(added['rows'])\n",
    "elements.extend(added['elements'])\n",
    "vecs = torch.cat([vecs, torch.from_numpy(added['vecs'])],0)\n",
    "len(rows), len(elements), vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46915, torch.Size([47211, 300]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements = np.array(elements)\n",
    "table = dict(zip(elements,vecs))\n",
    "len(table.keys()), vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mentions = {}\n",
    "for i, row in enumerate(rows):\n",
    "    for w in row:\n",
    "        if w not in mentions:\n",
    "            mentions[w] = []\n",
    "        mentions[w].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_connections(picks):\n",
    "    matches = set()\n",
    "    for q in picks:\n",
    "        matches.update(mentions[q])\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_closest(query, vecs, k=2):\n",
    "    \n",
    "    D = l2(query, vecs)\n",
    "    return torch.topk(D,k,dim=-1,largest=False, sorted=False)\n",
    "\n",
    "def convert(words, lang):\n",
    "    return torch.stack([lang[w] for w in words])\n",
    "    return torch.from_numpy(np.stack([lang.get_word_vector(w) for w in words])).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def solve(q):\n",
    "    \n",
    "    words = topk(q['question']['stem'])\n",
    "    \n",
    "    v = convert(words, lang)\n",
    "    \n",
    "    cls = get_closest(v, vecs)[1]\n",
    "    \n",
    "    conns = get_connections(elements[cls].reshape(-1))\n",
    "    \n",
    "    wopts = set()\n",
    "    for i in conns:\n",
    "        wopts.update(rows[i])\n",
    "    wopts = list(wopts)\n",
    "    \n",
    "    opts = torch.from_numpy(np.stack([table[w] for w in wopts])).float()\n",
    "    \n",
    "    lbls = []\n",
    "    for a in q['question']['choices']:\n",
    "        lbl = a['label']\n",
    "        v = convert(topk(a['text']), lang).view(-1,300)\n",
    "        nb = get_closest(v, opts, k=10)[0]\n",
    "        conf = 1/nb.mean()\n",
    "        lbls.append((lbl,conf))\n",
    "    \n",
    "    sol = sorted(lbls, key=lambda x: x[1])[-1][0]\n",
    "    return sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true = [q['answerKey'] for q in questions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/432 1.0000\n",
      "11/432 0.1818\n",
      "21/432 0.1905\n",
      "31/432 0.2903\n",
      "41/432 0.2195\n",
      "51/432 0.2157\n",
      "61/432 0.2295\n",
      "71/432 0.2254\n",
      "81/432 0.2469\n",
      "91/432 0.2857\n",
      "101/432 0.2772\n",
      "111/432 0.2883\n",
      "121/432 0.3058\n",
      "131/432 0.3053\n",
      "141/432 0.2979\n",
      "151/432 0.2914\n",
      "161/432 0.2981\n",
      "171/432 0.2865\n",
      "181/432 0.2873\n",
      "191/432 0.2827\n",
      "201/432 0.2886\n",
      "211/432 0.2891\n",
      "221/432 0.2805\n",
      "231/432 0.2771\n",
      "241/432 0.2780\n",
      "251/432 0.2749\n",
      "261/432 0.2759\n",
      "271/432 0.2804\n",
      "281/432 0.2776\n",
      "291/432 0.2784\n",
      "301/432 0.2757\n",
      "311/432 0.2797\n",
      "321/432 0.2804\n",
      "331/432 0.2749\n",
      "341/432 0.2698\n",
      "351/432 0.2764\n",
      "361/432 0.2825\n",
      "371/432 0.2830\n",
      "381/432 0.2835\n",
      "391/432 0.2864\n",
      "401/432 0.2868\n",
      "411/432 0.2920\n",
      "421/432 0.2898\n",
      "431/432 0.2877\n"
     ]
    }
   ],
   "source": [
    "sols = []\n",
    "correct = 0\n",
    "for i, q in enumerate(questions):\n",
    "    sol = solve(q)\n",
    "    if sol == true[i]:\n",
    "        correct += 1\n",
    "    sols.append(sol)\n",
    "    if i % 10 == 0:\n",
    "        print('{}/{} {:.4f}'.format(i+1,len(questions), correct/(i+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 0.2870\n"
     ]
    }
   ],
   "source": [
    "print('Done {:.4f}'.format(correct/(i+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCACACCAABCBCCCDDABAAADADCBACBDCDCDDAACACDABAAACCDACBDBAACBCDAABCBABDADAACDBABBCDBADCADDACDBBCADBBDDDABACDDCACDCDAACCABDCBADAACDDBBADBDDACBCBBBDAACBBBBCDDABDBCDBDCDDCDDACCCACCCDBCBAAADCADCBBDADADCBBACCBBBCDBABADBACAACCBCDCBBCCBBADDAACCBDCCADCDCACACADDDDCACDDBBADCBBACBBCBADCBADBDBDAACBDCCBBACAADDCBDDDDDCBBBACADAADCCCBBACCACABCCABCDDCBDDCDDCCBBBABBABCBBBBDBBCCBBCCACBBCAACAAADBCDDCACBCABBDBCBABCDBDBCABCDBDBDAACACCDBDBADBBBBBDBBBBAC\n"
     ]
    }
   ],
   "source": [
    "print(''.join(true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBDABDDCBACBBACACCDBBADADDAAAACBADAACBBDACBDCCDCDCABADDACDADDDACDCACBBBDCBBBCDBCDCDCCADDACCDBACBBCBBBADBBDBCBCBDAACDCABDBCADCBADCADABACBBBADBCDDCBAABACCDBBDAAADBBBBABCDBBAAADCBBBDABDADBDAAADBCAADCBDBBAACDBABCCADDDDADDDAAADBDBBBDBBBBCCCACCDDBAACBADAAABBACACCAAADDCADCDBBDDDCBCCBCCBDBCBDDCDCAADBDBABDDDCDCBCCDCCADAABAADDBDDACBDDABDBBBABDACBDCDAABBCDBACCBDBDBBBDCCAABAACACABDCABCACDBBADCCAACDCADBCCBBABBCDCCADCDAADCADDADABBDAABDACBADDB\n"
     ]
    }
   ],
   "source": [
    "print(''.join(sols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# elem: 0.2894\n",
    "# true: CCACACCAABCBCCCDDABAAADADCBACBDCDCDDAACACDABAAACCDACBDBAACBCDAABCBABDADAACDBABBCDBADCADDACDBBCADBBDDDABACDDCACDCDAACCABDCBADAACDDBBADBDDACBCBBBDAACBBBBCDDABDBCDBDCDDCDDACCCACCCDBCBAAADCADCBBDADADCBBACCBBBCDBABADBACAACCBCDCBBCCBBADDAACCBDCCADCDCACACADDDDCACDDBBADCBBACBBCBADCBADBDBDAACBDCCBBACAADDCBDDDDDCBBBACADAADCCCBBACCACABCCABCDDCBDDCDDCCBBBABBABCBBBBDBBCCBBCCACBBCAACAAADBCDDCACBCABBDBCBABCDBDBCABCDBDBDAACACCDBDBADBBBBBDBBBBAC\n",
    "# pred: CBDABDDCBACBCACACCDBBADADDAAAADBADAACBBDACBDCCBCDCABADDACDADDDACDCDCBBBDCBBBCDBCDCDCCCDDACCDBACBBCBBBADBBDBCBCBDAACDCABDBCADCBADCADACACBBBADBCDDABAABACCDBBDAAADBBBBABCDBBAAADCBBBDCBDADBDAAADBCAADCBDBBABCDBABCCADDDDADDDAAADBDBBBDBBBBCCCACCDDBAACBADAAABBACACCAAADDCADCDBBDDDCBCCBCCBDBCBDDCDCAADBDBABDDDCDCBCCDCDADAABAADDBDDAABDDABDBBBABDAABACDAABBCDBACCBDBDDBBDCCAABAACACABDCABCACDBBADCCAACDCADBCADBAABCDCCADCDCADCADDADABDDACBDACBADDB\n",
    "\n",
    "# elem-full: 0.2847\n",
    "# pred: CBDABDDCBDCBBACACCDBBADADDCAAADAADBACBDDACBDCCDCDCABADDACDADDDACDCACBBBDCBBBCDBCDCDCCCDDACCDCAABBCBBBADBDDBCBCADAACDCABDBCADCBADCADABACBABADBCDBCBAABACADBBCAAADBBBBABCDBBAAADCABBDCBDADBDAAADBCAADCBDBBCACDBABCCADDDDADDDABADBDBBBDBBBBCCCACCDDBAACBADAAABBACACCAABDDCADCDBBDDDCBCCBCCBDBBADDCDCAADBDBABDDDCDCDCCDCDADAABAADDADDACBDDABDCBBABDACBDCDAABACDBACCBDBDBBBDCCAABAACACABDCABBACDBBADCCAACDCADBCCBBABBCDCCADBDAADCADDADABDDAABDACBCDDB\n",
    "\n",
    "# elem-filter: 0.2870\n",
    "# pred: CBDABDDCBACBBACACCDBBADADDAAAACBADAACBBDACBDCCDCDCABADDACDADDDACDCACBBBDCBBBCDBCDCDCCADDACCDBACBBCBBBADBBDBCBCBDAACDCABDBCADCBADCADABACBBBADBCDDCBAABACCDBBDAAADBBBBABCDBBAAADCBBBDABDADBDAAADBCAADCBDBBAACDBABCCADDDDADDDAAADBDBBBDBBBBCCCACCDDBAACBADAAABBACACCAAADDCADCDBBDDDCBCCBCCBDBCBDDCDCAADBDBABDDDCDCBCCDCCADAABAADDBDDACBDDABDBBBABDACBDCDAABBCDBACCBDBDBBBDCCAABAACACABDCABCACDBBADCCAACDCADBCCBBABBCDCCADCDAADCADDADABBDAABDACBADDB\n",
    "\n",
    "# 8th: 0.3072\n",
    "# true: BDDBCCDCBDACDBDCDADBDBABDDBBDCBCBCCBCBCACDBDBABCBAAABBABCADDCBABCBCBDDCCCDCAABCDADABDADCCACCCDDCBBACDBCACCAAABABDCABCCDCDDACBBCBADDBCCACACCDADADDAACDBBCADCCBBDADBBDAABACABADCABDDDCDCBBDDDDACADAACBCACACBBBCBDCBCCACCCBCCACCADDCBBBABCABBACACDCBCCBCDCADADBABDACADABBDDCBBDCBDADBBCCCCCBBDCDCDDBCBCD\n",
    "# pred: BDDADABDBDBADCDCADCDCABBCABCBCBACBDDBCCDCDDCADCAABDABBDCBBCDABDBDBCDCAACDABCABCBDDADDCCAAABCAABBBBBCCCABCCCCCBCCDDABCADDDAABAADDDDBCACDACADDBCDBBDCABBCABDCDCDADCBAAADBADDBBDCDBBDCDDDADBBBCCCAADBBCCDCDBDBBDBDDCDCBACBACADDBBABBDDBDAAACBBACBAABBCDACDADCCBCCDDCAADAABBBBCDDCBDADDBBBAADDACACADBDAAD\n",
    "\n",
    "# 8th-full: 0.2969\n",
    "# pred: CDDADADDBABADCDCADCDDABDCABCBCDACBDDBCCDCDDCADCAABDACBACBBCDABDBDBCCCAACDABCABABDCCADCCAABBCADBCCBDCCCABCCCCCBCCDDABCDDDDAABAADDDDBCACDACCDDBCDDBBCABBCABDCDCDADCBAAADBADDBBDCDBBDCDDDADBBBCCCAADBBCCDCDBDBBDBDDCDCBACBACADDBBABBDDBDAAACBBACBAABBCDACDADCCBCCDDCAADAABBBBCDDCBDABDBBAAADDACACBDBDAAA\n",
    "\n",
    "# 8th-filter: 0.3106\n",
    "# pred: BDDADABDBDBADCDCADCDCABBCABCBCBACBDDBCCDCDDCADCAABDABBACBBCDABDBDBCDCAACDABCABCBDCADDCCAAABCAABBBBDCCCABCCCCCBCCDDABCACDDAABAADDDDBCACDACCDDBCDBBBCABBCABDCDCDADCBAAADBADDBBDCDBBDCDDDADBBBCCCAADBBCCDCDBDBBDBDDCDCBACBACADDBBABBDDBDAAACBBACBAABBCDACDADCCBCCDDCAADAABBBBCDDCBDADDBBBAADDACACADBDAAD\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
